{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# job1:\n",
    "\n",
    "Anti-Terrorism Intelligence Analysis\n",
    "\n",
    "Metro\n",
    "\n",
    "[Link](https://www.indeed.com/jobs?q=Intelligence%20Analysis&l=Washington%2C%20DC&vjk=2666edf71c7b3200&advn=477295927342672)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# job2:\n",
    "\n",
    "Counterintelligence Investigator\n",
    "\n",
    "Leido\n",
    "\n",
    "[Link](https://www.indeed.com/viewjob?jk=696eb25ddaa842f0&tk=1d6gov55q270i002&from=serp&vjs=3&advn=8766782434770833&adid=149689977&sjdu=0ZFwD5rbjMRcHz87Kzx_g0cw0T9TkucWQF5N5b0w5Auz7smrsuwW8GraeB26d0QsuqSNiDiEm65m5BjzkzMUQDZkYE2IFBHGyBO7C8I20FLqDvUZ-Tz7kgvVVMmsL9MNzbHflQ-VK8Tc6bHMIqKUL7g3WQtOk7nlIWXpMKPdZ9g0Nm_SJd9fWSAsMFSKnXIb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt        \n",
    "from collections import Counter        \n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "  \n",
    "book = xlwt.Workbook() # create a new excel file\n",
    "sheet_test = book.add_sheet('word_count') # add a new sheet\n",
    "i = 0\n",
    "sheet_test.write(i,0,'word') # write the header of the first column\n",
    "sheet_test.write(i,1,'count') # write the header of the second column\n",
    "sheet_test.write(i,2,'ratio') # write the header of the third column\n",
    "    \n",
    "with open('Job2.txt','r',encoding='utf-8', errors = 'ignore') as text_word: # define the location of your txt file\n",
    "     \n",
    "    # convert all the word into lower cases\n",
    "    # filter out stop words\n",
    "    word_list = [i for i in text_word.read().lower().split() if i not in stop]\n",
    "    word_total = word_list.__len__()\n",
    "     \n",
    "    count_result =  Counter(word_list)\n",
    "    for result in count_result.most_common(10):\n",
    "        i = i+1 \n",
    "        sheet_test.write(i,0,result[0])\n",
    "        sheet_test.write(i,1,result[1])\n",
    "        sheet_test.write(i,2,(result[1]/word_total))\n",
    "    \n",
    "book.save('Job2.xls')# define the location of your excel file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt        \n",
    "from collections import Counter        \n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "  \n",
    "book = xlwt.Workbook() # create a new excel file\n",
    "sheet_test = book.add_sheet('word_count') # add a new sheet\n",
    "i = 0\n",
    "sheet_test.write(i,0,'word') # write the header of the first column\n",
    "sheet_test.write(i,1,'count') # write the header of the second column\n",
    "sheet_test.write(i,2,'ratio') # write the header of the third column\n",
    "    \n",
    "with open('Job.txt','r',encoding='utf-8', errors = 'ignore') as text_word: # define the location of your txt file\n",
    "     \n",
    "    # convert all the word into lower cases\n",
    "    # filter out stop words\n",
    "    word_list = [i for i in text_word.read().lower().split() if i not in stop]\n",
    "    word_total = word_list.__len__()\n",
    "     \n",
    "    count_result =  Counter(word_list)\n",
    "    for result in count_result.most_common(10):\n",
    "        i = i+1 \n",
    "        sheet_test.write(i,0,result[0])\n",
    "        sheet_test.write(i,1,result[1])\n",
    "        sheet_test.write(i,2,(result[1]/word_total))\n",
    "    \n",
    "book.save('Job1.xls')# define the location of your excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Job1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Job2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'applicants', 'This', 'health', 'route', 'Forecast', '(GED).', 'Review', 'Collect', 'Personal', 'resources.', 'Graduation', 'religion,', 'exercises', 'monitoring,', 'fide', 'education', 'Monitor', 'Homeland', 'homeland', 'Anti-Terrorism', 'useful,', 'Blend,', 'processes', 'requires', 'if', 'preliminary', 'MINIMUM', 'add', 'analysis;', 'validate', 'Participate', 'creed,', 'research,', 'equipment,', 'include', 'primary', 'appropriate', 'providing', 'employment', 'timely,', 'Federal', 'available', 'regional', 'Applicants', 'informed', 'Research,', 'table-tops', 'Certification/Licensure', 'investigations', 'open', 'situational', 'one', 'employer.', 'OTHER', 'Bureau', 'counter-terrorism/intelligence', 'contractor,', 'expediting', 'Vehicle', 'asset', 'MTPD', 'Support', 'enforcement.', 'twelve', 'Obtain', 'any', 'analysis.', 'whose', 'practices', 'department', 'Police', 'either', 'perform', 'national', 'sharing.', 'understanding', 'replace', 'incumbent', 'assessments', 'accommodations.', 'will', 'against', 'them', 'Medical', 'sources.', 'awareness,', 'Criteria:', 'local', 'regard', 'hiring', 'implications.', 'jurisdictional', 'consideration', 'work', 'groups', 'veteran,', 'sex,', 'gender,', 'intended', 'certificate', 'position,', 'analyze', 'official', 'accessible', 'identity,', 'media', 'bona', 'descriptions', 'It', 'SUMMARY', 'hire', 'free', 'Motor', 'recruitment.', 'abreast', 'experience.', 'departmental', 'qualified', 'exists.', 'Report', 'function', 'genetic', 'receive', 'property', 'orientation,', 'examination', 'Identify,', 'specific', 'Capital', 'trends', 'Evaluation', 'QUALIFICATIONS', 'Equal', 'Nor', 'mental', 'employees', 'discrimination.', 'pursuant', 'Affirmative', 'school', 'Gather', 'complete', 'order', 'protected', 'assign,', 'Metro', 'screening', 'analyze,', 'obtain', 'completion', 'action.', 'debriefs', 'Opportunity', 'federal', 'Verification', 'National', 'Department', 'it', 'maintain', 'sexual', 'comprehensive', 'limit', 'given', 'create', 'medical', 'methodologies', 'managers', 'possession', 'arrests/investigations.', 'following:', 'Check', 'Consideration', 'Interview', 'using', 'reasonable', 'training.', 'Perform', 'Asses', 'direct', 'under', 'best', 'publish', 'origin,', 'independent', 'global,', 'Investigations', 'gang', 'keep', 'operations.', 'process', 'WMATA', 'way', 'Metropolitan', 'Apply', 'officer', '5', 'Education', 'interview', 'Analysis', 'alcohol', 'qualification', 'teamwork', 'conflicts', 'not', 'arrests', 'Ability', 'combination', 'physical', '(HSIIB)', 'workshops,', 'race,', 'equivalency', 'duties', 'supervisors', 'environment,', 'without', 'intersect', 'vacant', 'navigate', 'disability,', 'investigate', 'Successful', 'Skills', 'tested.', 'status', 'particular', '.', 'gathering', 'purposes.', 'Our', 'crime', 'Background', 'year', 'Action', 'potential', 'supervision.', 'background', 'working', 'safety', 'impacting', 'well', 'listed', 'forecasting', 'Group:', 'state', 'risk', 'WMATA.', 'record', 'FUNCTIONS', 'intelligence,', 'Criminal', 'Washington', 'demonstrate', 'coordinate', 'posting', 'resolve', 'ability', 'confirmation', 'this', 'Assessments', 'environments', 'age,', '(NCR)', 'designed', 'color,', 'criteria', 'product', 'evaluate,', 'security.', '(1)', 'Closing:', 'representatives,', 'right', 'All', 'their', 'owners.', 'welfare,', 'announcement', 'Authority,', 'Satisfactorily', 'Transit', 'investigations.', 'Clearance.', 'counter-terrorism', 'anti-terrorism', 'skills,', 'federal,', 'being', 'effecting', 'social', '/', 'health,', 'networks', 'description.', 'patterns', 'Attend', 'occupational', 'months', 'sections', 'enforcement,', 'ESSENTIAL', 'transit', 'Liaison', 'resumes', 'based', 'gender', 'investigation.', 'Region', 'incidents/events', 'internally', 'basis', 'bureaus', 'stay', 'conferences,', 'law,', 'position.', 'control', 'accurate', 'should', '(12)', 'more', 'except', 'generate', 'drug', 'high', 'intelligence/investigation.', 'essential', 'criminal', 'Area', 'outlets'}\n",
      "{'solutions.', 'relationships', 'foreign', 'Government', 'facts', 'addressed.', 'reporting', 'collaborate', 'countering', 'developed', 'counterintelligence', 'Reuters,', 'visitors', 'DSS,', 'Publisher,', 'affairs.', 'MCB', 'experience;', 'fulfillment', 'proper', 'Qualifications', 'ascertain', 'make', 'government', 'make/argue', 'range', 'inquiry.', 'Nexis.', 'lieu', 'CI', 'ensure', 'once', 'complete,', 'inquiries,', 'Assist', 'reasoned', 'analysis,', 'Microsoft', 'accuracy.', 'MCB.', 'communication', 'variety', 'instruction.', 'senior', 'judgments', 'future', 'VA.', 'oral', 'Substantial', 'Responsibilities', 'software', 'persuade', 'threats,', 'contact', 'Corporate', 'join', 'Investigator', 'presentation', 'international', 'Point,', 'Quantico', 'Cl', 'presentations', 'Operational', 'team', 'industry', 'implications', 'Word.', 'Excel,', 'identified', 'consider', 'Basic', 'collaborative', 'Write,', 'degree', 'personnel', 'skills.', 'analytic', 'expert', 'week)', 'full', 'Community', 'reports.', 'Highly-developed', 'traveling', 'prior', 'guidance;', 'Notebook;', 'terminology;', 'debrief', 'produce', 'master', 'advice,', 'investigations,', 'Power', 'interest', 'wide', 'Reston,', 'comfortable', 'those', 'review,', 'areas', 'cleared', 'concerning', 'development', 'position;', 'hybrid', 'evolution', 'Brief', 'counterparts', 'effectively', 'resources', 'Accurint,', 'Access,', 'Candidates', 'present', 'provided', \"Community's\", 'program', 'Related', 'assets', 'Analyst', 'SCI', 'US', 'recommendation', 'our', 'well-founded', \"Bachelor's\", 'others', 'collate', 'Primary', 'include:', '(reimbursable).', '8+', 'emerging', 'coordination,', 'leadership.', 'community.', 'concepts', 'identify', 'sources', 'Review,', 'educational/', 'written', 'tools', 'FBI,', 'Analyze', 'deliver', 'information;', 'associated', 'critical', 'prevention', 'entities', 'abstract', 'Palentir', 'possible,', '(once', 'defense', 'additional', 'accredited', 'citizenship', 'immediacy', 'Thomson', 'eligibility', 'Excellent', 'services', 'overseas', 'counterintelligence,', 'agencies,', 'Description:', 'hosting', 'employees,', 'necessary', 'threat,', 'Investigate', 'efforts', 'educational', \"years'\", 'acquiring', 'during', 'suspicious', 'risks.', 'activity', 'Developing', 'evaluate', 'techniques,', 'Plans.', 'Maintain', 'Leidos', 'week', 'clearly', 'Lexis', 'delivering', 'Travel', 'functional', 'findings', 'explain', 'Detail-oriented', 'and,', 'procedures,', '(OPSEC)', 'travel', 'Familiarity', 'degree.', 'skills', 'corroborated', 'speaking.', 'Counterintelligence', 'applications', 'operations,', 'share', 'university', 'Prepare', 'such'}\n"
     ]
    }
   ],
   "source": [
    "with open('Job.txt','r', encoding='utf-8', errors = 'ignore') as job1: \n",
    "    with open('job2.txt','r', encoding='utf-8', errors = 'ignore') as job2: \n",
    "        job1_str =job1.read()\n",
    "        job2_str =job2.read()\n",
    "        \n",
    "        job1_set = set (job1_str.split())\n",
    "        job2_set = set(job2_str.split())\n",
    "        \n",
    "        print(job1_set.difference(job2_set))\n",
    "        print(job2_set.difference(job1_set))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "with open('Job.txt','r', encoding='utf-8', errors = 'ignore') as job1: \n",
    "    with open('job2.txt','r', encoding='utf-8', errors = 'ignore') as job2: \n",
    "        job1_str =job1.read()\n",
    "        job2_str =job2.read()\n",
    "        print(fuzz.token_sort_ratio(job1_str,job2_str))\n",
    "        \n",
    "#        job1_set = set (job1_str.split())\n",
    "#       job2_set = set(job2_str.split())\n",
    "        \n",
    "#        print(job1_set.difference(job2_set))\n",
    "#        print(job2_set.difference(job1_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
